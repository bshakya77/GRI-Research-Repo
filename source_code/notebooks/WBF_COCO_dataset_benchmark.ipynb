{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ensemble_boxes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Dt_GHrTYSmU",
        "outputId": "b3602fd8-7ea4-4fc3-9724-9da1ca6184f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ensemble_boxes\n",
            "  Downloading ensemble_boxes-1.0.9-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ensemble_boxes) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ensemble_boxes) (1.5.3)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from ensemble_boxes) (0.56.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->ensemble_boxes) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->ensemble_boxes) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ensemble_boxes) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ensemble_boxes) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->ensemble_boxes) (1.16.0)\n",
            "Installing collected packages: ensemble_boxes\n",
            "Successfully installed ensemble_boxes-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip './benchmark.zip' -d './benchmark/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sif_8iZZrhI",
        "outputId": "b7d6a97e-b4c7-400c-8e8e-c40f6c41c14c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open ./benchmark.zip, ./benchmark.zip.zip or ./benchmark.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMQKq_NoYNbm",
        "outputId": "04f77426-061b-4f07-cc83-7747b579d667"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use processes: 1\n",
            "Read ./benchmark/EffNetB4-preds.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d28a1d899d80>:194: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  s = pd.read_csv(pred_filenames[j], dtype={'img_id': np.str, 'label': np.str})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read ./benchmark/EffNetB4-mirror-preds.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d28a1d899d80>:194: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  s = pd.read_csv(pred_filenames[j], dtype={'img_id': np.str, 'label': np.str})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read ./benchmark/EffNetB5-preds.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d28a1d899d80>:194: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  s = pd.read_csv(pred_filenames[j], dtype={'img_id': np.str, 'label': np.str})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read ./benchmark/EffNetB5-mirror-preds.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d28a1d899d80>:194: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  s = pd.read_csv(pred_filenames[j], dtype={'img_id': np.str, 'label': np.str})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read ./benchmark/EffNetB6-preds.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d28a1d899d80>:194: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  s = pd.read_csv(pred_filenames[j], dtype={'img_id': np.str, 'label': np.str})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read ./benchmark/EffNetB6-mirror-preds.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d28a1d899d80>:194: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  s = pd.read_csv(pred_filenames[j], dtype={'img_id': np.str, 'label': np.str})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read ./benchmark/EffNetB7-preds.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d28a1d899d80>:194: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  s = pd.read_csv(pred_filenames[j], dtype={'img_id': np.str, 'label': np.str})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read ./benchmark/EffNetB7-mirror-preds.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d28a1d899d80>:194: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  s = pd.read_csv(pred_filenames[j], dtype={'img_id': np.str, 'label': np.str})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read ./benchmark/DetRS-valid.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d28a1d899d80>:194: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  s = pd.read_csv(pred_filenames[j], dtype={'img_id': np.str, 'label': np.str})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read ./benchmark/DetRS-mirror-valid.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d28a1d899d80>:194: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  s = pd.read_csv(pred_filenames[j], dtype={'img_id': np.str, 'label': np.str})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read ./benchmark/DetRS_resnet50-valid.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d28a1d899d80>:194: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  s = pd.read_csv(pred_filenames[j], dtype={'img_id': np.str, 'label': np.str})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read ./benchmark/DetRS_resnet50-mirror-valid.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d28a1d899d80>:194: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  s = pd.read_csv(pred_filenames[j], dtype={'img_id': np.str, 'label': np.str})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read ./benchmark/yolov5x_tta.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d28a1d899d80>:194: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  s = pd.read_csv(pred_filenames[j], dtype={'img_id': np.str, 'label': np.str})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start process: 0 IDs to proc: 5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d28a1d899d80>:159: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  merged_labels = np.array(merged_labels_string, dtype=np.str)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run time: 258.45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d28a1d899d80>:28: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  s = pd.read_csv(csv_path, dtype={'img_id': np.str, 'label': np.str})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.69s)\n",
            "creating index...\n",
            "index created!\n",
            "(2565833, 7)\n",
            "[[1.00000000e+03 1.16464013e+02 1.49698190e+02 8.08876352e+01\n",
            "  2.32439218e+02 8.77192800e-01 1.00000000e+00]\n",
            " [1.00000000e+03 5.05512922e+02 1.91346888e+02 1.33588902e+02\n",
            "  2.83817040e+02 8.11741000e-01 1.00000000e+00]\n",
            " [1.00000000e+03 4.10497702e+02 2.09786952e+02 1.13947642e+02\n",
            "  2.66456698e+02 7.88022340e-01 1.00000000e+00]\n",
            " [1.00000000e+03 2.64580672e+02 9.72633216e+01 9.02626176e+01\n",
            "  3.13843958e+02 7.59509200e-01 1.00000000e+00]\n",
            " [1.00000000e+03 3.29545248e+02 1.53777566e+02 8.68598976e+01\n",
            "  3.15882082e+02 7.53836000e-01 1.00000000e+00]]\n",
            "Loading and preparing results...\n",
            "Converting ndarray to lists...\n",
            "(2565833, 7)\n",
            "0/2565833\n",
            "1000000/2565833\n",
            "2000000/2565833\n",
            "DONE (t=19.93s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=137.26s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=43.94s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.560\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.741\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.621\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.403\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.606\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.696\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.404\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.685\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.756\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.631\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.795\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.875\n",
            "[0.55964744 0.74054002 0.62126173 0.40271438 0.60579838 0.69619785\n",
            " 0.404245   0.68515546 0.75622066 0.63122753 0.79484934 0.8754414 ]\n"
          ]
        }
      ],
      "source": [
        "# coding: utf-8\n",
        "__author__ = 'ZFTurbo: https://kaggle.com/zfturbo'\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import time\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "from multiprocessing import Pool, Process, cpu_count, Manager\n",
        "from ensemble_boxes import *\n",
        "\n",
        "\n",
        "def get_coco_annotations_data():\n",
        "    file_in = 'instances_val2017.json'\n",
        "    images = dict()\n",
        "    with open(file_in) as json_file:\n",
        "        data = json.load(json_file)\n",
        "        for i in range(len(data['images'])):\n",
        "            image_id = data['images'][i]['id']\n",
        "            images[image_id] = data['images'][i]\n",
        "\n",
        "    return images\n",
        "\n",
        "\n",
        "def get_coco_score(csv_path):\n",
        "    images = get_coco_annotations_data()\n",
        "    s = pd.read_csv(csv_path, dtype={'img_id': np.str, 'label': np.str})\n",
        "\n",
        "    out = np.zeros((len(s), 7), dtype=np.float64)\n",
        "    out[:, 0] = s['img_id']\n",
        "    ids = s['img_id'].astype(np.int32).values\n",
        "    x1 = s['x1'].values\n",
        "    x2 = s['x2'].values\n",
        "    y1 = s['y1'].values\n",
        "    y2 = s['y2'].values\n",
        "    for i in range(len(s)):\n",
        "        width = images[ids[i]]['width']\n",
        "        height = images[ids[i]]['height']\n",
        "        out[i, 1] = x1[i] * width\n",
        "        out[i, 2] = y1[i] * height\n",
        "        out[i, 3] = (x2[i] - x1[i]) * width\n",
        "        out[i, 4] = (y2[i] - y1[i]) * height\n",
        "    out[:, 5] = s['score'].values\n",
        "    out[:, 6] = s['label'].values\n",
        "\n",
        "    filename = 'instances_val2017.json'\n",
        "    coco_gt = COCO(filename)\n",
        "    detections = out\n",
        "    print(detections.shape)\n",
        "    print(detections[:5])\n",
        "    image_ids = list(set(detections[:, 0]))\n",
        "    coco_dt = coco_gt.loadRes(detections)\n",
        "    coco_eval = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
        "    coco_eval.params.imgIds = image_ids\n",
        "    coco_eval.evaluate()\n",
        "    coco_eval.accumulate()\n",
        "    coco_eval.summarize()\n",
        "    coco_metrics = coco_eval.stats\n",
        "    print(coco_metrics)\n",
        "    return coco_metrics, detections\n",
        "\n",
        "\n",
        "def process_single_id(id, res_boxes, weights, params):\n",
        "    run_type = params['run_type']\n",
        "    verbose = params['verbose']\n",
        "\n",
        "    # print('Go for ID: {}'.format(id))\n",
        "    boxes_list = []\n",
        "    scores_list = []\n",
        "    labels_list = []\n",
        "    labels_to_use_forward = dict()\n",
        "    labels_to_use_backward = dict()\n",
        "\n",
        "    for i in range(len(res_boxes[id])):\n",
        "        boxes = []\n",
        "        scores = []\n",
        "        labels = []\n",
        "\n",
        "        dt = res_boxes[id][i]\n",
        "\n",
        "        for j in range(0, len(dt)):\n",
        "            lbl = dt[j][5]\n",
        "            scr = float(dt[j][4])\n",
        "            box_x1 = float(dt[j][0])\n",
        "            box_y1 = float(dt[j][1])\n",
        "            box_x2 = float(dt[j][2])\n",
        "            box_y2 = float(dt[j][3])\n",
        "\n",
        "            if box_x1 >= box_x2:\n",
        "                if verbose:\n",
        "                    print('Problem with box x1 and x2: {}. Skip it'.format(dt[j]))\n",
        "                continue\n",
        "            if box_y1 >= box_y2:\n",
        "                if verbose:\n",
        "                    print('Problem with box y1 and y2: {}. Skip it'.format(dt[j]))\n",
        "                continue\n",
        "            if scr <= 0:\n",
        "                if verbose:\n",
        "                    print('Problem with box score: {}. Skip it'.format(dt[j]))\n",
        "                continue\n",
        "\n",
        "            boxes.append([box_x1, box_y1, box_x2, box_y2])\n",
        "            scores.append(scr)\n",
        "            if lbl not in labels_to_use_forward:\n",
        "                cur_point = len(labels_to_use_forward)\n",
        "                labels_to_use_forward[lbl] = cur_point\n",
        "                labels_to_use_backward[cur_point] = lbl\n",
        "            labels.append(labels_to_use_forward[lbl])\n",
        "\n",
        "        boxes = np.array(boxes, dtype=np.float32)\n",
        "        scores = np.array(scores, dtype=np.float32)\n",
        "        labels = np.array(labels, dtype=np.int32)\n",
        "\n",
        "        boxes_list.append(boxes)\n",
        "        scores_list.append(scores)\n",
        "        labels_list.append(labels)\n",
        "\n",
        "    # Empty predictions for all models\n",
        "    if len(boxes_list) == 0:\n",
        "        return np.array([]), np.array([]), np.array([])\n",
        "\n",
        "    if run_type == 'wbf':\n",
        "        merged_boxes, merged_scores, merged_labels = weighted_boxes_fusion(boxes_list, scores_list, labels_list,\n",
        "                                                                       weights=weights, iou_thr=params['intersection_thr'],\n",
        "                                                                       skip_box_thr=params['skip_box_thr'],\n",
        "                                                                           conf_type=params['conf_type'])\n",
        "    elif run_type == 'wbf_exp':\n",
        "        merged_boxes, merged_scores, merged_labels = weighted_boxes_fusion_experimental(boxes_list, scores_list, labels_list,\n",
        "                                                                       weights=weights, iou_thr=params['intersection_thr'],\n",
        "                                                                       skip_box_thr=params['skip_box_thr'],\n",
        "                                                                           conf_type=params['conf_type'])\n",
        "    elif run_type == 'nms':\n",
        "        iou_thr = params['iou_thr']\n",
        "        merged_boxes, merged_scores, merged_labels = nms(boxes_list, scores_list, labels_list, weights=weights, iou_thr=iou_thr)\n",
        "    elif run_type == 'soft-nms':\n",
        "        iou_thr = params['iou_thr']\n",
        "        sigma = params['sigma']\n",
        "        thresh = params['thresh']\n",
        "        merged_boxes, merged_scores, merged_labels = soft_nms(boxes_list, scores_list, labels_list,\n",
        "                                                              weights=weights, iou_thr=iou_thr, sigma=sigma, thresh=thresh)\n",
        "    elif run_type == 'nmw':\n",
        "        merged_boxes, merged_scores, merged_labels = non_maximum_weighted(boxes_list, scores_list, labels_list,\n",
        "                                                                       weights=weights, iou_thr=params['intersection_thr'],\n",
        "                                                                       skip_box_thr=params['skip_box_thr'])\n",
        "\n",
        "    # print(len(boxes_list), len(merged_boxes))\n",
        "    if 'limit_boxes' in params:\n",
        "        limit_boxes = params['limit_boxes']\n",
        "        if len(merged_boxes) > limit_boxes:\n",
        "            merged_boxes = merged_boxes[:limit_boxes]\n",
        "            merged_scores = merged_scores[:limit_boxes]\n",
        "            merged_labels = merged_labels[:limit_boxes]\n",
        "\n",
        "    # Rename labels back\n",
        "    merged_labels_string = []\n",
        "    for m in merged_labels:\n",
        "        merged_labels_string.append(labels_to_use_backward[m])\n",
        "    merged_labels = np.array(merged_labels_string, dtype=np.str)\n",
        "\n",
        "    # Create IDs array\n",
        "    ids_list = [id] * len(merged_labels)\n",
        "\n",
        "    return merged_boxes.copy(), merged_scores.copy(), merged_labels.copy(), ids_list.copy()\n",
        "\n",
        "\n",
        "def process_part_of_data(proc_number, return_dict, ids_to_use, res_boxes, weights, params):\n",
        "    print('Start process: {} IDs to proc: {}'.format(proc_number, len(ids_to_use)))\n",
        "    result = []\n",
        "    for id in ids_to_use:\n",
        "        merged_boxes, merged_scores, merged_labels, ids_list = process_single_id(id, res_boxes, weights, params)\n",
        "        # print(merged_boxes.shape, merged_scores.shape, merged_labels.shape, len(ids_list))\n",
        "        result.append((merged_boxes, merged_scores, merged_labels, ids_list))\n",
        "    return_dict[proc_number] = result.copy()\n",
        "\n",
        "\n",
        "def ensemble_predictions(pred_filenames, weights, params):\n",
        "    verbose = False\n",
        "    if 'verbose' in params:\n",
        "        verbose = params['verbose']\n",
        "\n",
        "    start_time = time.time()\n",
        "    procs_to_use = max(cpu_count() // 2, 1)\n",
        "    # procs_to_use = 6\n",
        "    print('Use processes: {}'.format(procs_to_use))\n",
        "    weights = np.array(weights)\n",
        "\n",
        "    res_boxes = dict()\n",
        "    ref_ids = None\n",
        "    for j in range(len(pred_filenames)):\n",
        "        if weights[j] == 0:\n",
        "            continue\n",
        "        print('Read {}...'.format(pred_filenames[j]))\n",
        "        s = pd.read_csv(pred_filenames[j], dtype={'img_id': np.str, 'label': np.str})\n",
        "        s.sort_values('img_id', inplace=True)\n",
        "        s.reset_index(drop=True, inplace=True)\n",
        "        ids = s['img_id'].values\n",
        "        unique_ids = sorted(s['img_id'].unique())\n",
        "        if ref_ids is None:\n",
        "            ref_ids = tuple(unique_ids)\n",
        "        else:\n",
        "            if ref_ids != tuple(unique_ids):\n",
        "                print('Different IDs in ensembled CSVs! {} != {}'.format(len(ref_ids), len(unique_ids)))\n",
        "                s = s[s['img_id'].isin(ref_ids)]\n",
        "                s.sort_values('img_id', inplace=True)\n",
        "                s.reset_index(drop=True, inplace=True)\n",
        "                ids = s['img_id'].values\n",
        "        preds = s[['x1', 'y1', 'x2', 'y2', 'score', 'label']].values\n",
        "        single_res = dict()\n",
        "        for i in range(len(ids)):\n",
        "            id = ids[i]\n",
        "            if id not in single_res:\n",
        "                single_res[id] = []\n",
        "            single_res[id].append(preds[i])\n",
        "        for el in single_res:\n",
        "            if el not in res_boxes:\n",
        "                res_boxes[el] = []\n",
        "            res_boxes[el].append(single_res[el])\n",
        "\n",
        "    # Reduce weights if needed\n",
        "    weights = weights[weights != 0]\n",
        "\n",
        "    ids_to_use = sorted(list(res_boxes.keys()))\n",
        "    manager = Manager()\n",
        "    return_dict = manager.dict()\n",
        "    jobs = []\n",
        "    for i in range(procs_to_use):\n",
        "        start = i * len(ids_to_use) // procs_to_use\n",
        "        end = (i+1) * len(ids_to_use) // procs_to_use\n",
        "        if i == procs_to_use - 1:\n",
        "            end = len(ids_to_use)\n",
        "        p = Process(target=process_part_of_data, args=(i, return_dict, ids_to_use[start:end], res_boxes, weights, params))\n",
        "        jobs.append(p)\n",
        "        p.start()\n",
        "\n",
        "    for i in range(len(jobs)):\n",
        "        jobs[i].join()\n",
        "\n",
        "    results = []\n",
        "    for i in range(len(jobs)):\n",
        "        results += return_dict[i]\n",
        "\n",
        "    # p = Pool(processes=procs_to_use)\n",
        "    # results = p.starmap(process_single_id, zip(ids_to_use, repeat(weights), repeat(params)))\n",
        "\n",
        "    all_ids = []\n",
        "    all_boxes = []\n",
        "    all_scores = []\n",
        "    all_labels = []\n",
        "    for boxes, scores, labels, ids_list in results:\n",
        "        if boxes is None:\n",
        "            continue\n",
        "        all_boxes.append(boxes)\n",
        "        all_scores.append(scores)\n",
        "        all_labels.append(labels)\n",
        "        all_ids.append(ids_list)\n",
        "\n",
        "    all_ids = np.concatenate(all_ids)\n",
        "    all_boxes = np.concatenate(all_boxes)\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "    if verbose:\n",
        "        print(all_ids.shape, all_boxes.shape, all_scores.shape, all_labels.shape)\n",
        "\n",
        "    res = pd.DataFrame(all_ids, columns=['img_id'])\n",
        "    res['label'] = all_labels\n",
        "    res['score'] = all_scores\n",
        "    res['x1'] = all_boxes[:, 0]\n",
        "    res['x2'] = all_boxes[:, 2]\n",
        "    res['y1'] = all_boxes[:, 1]\n",
        "    res['y2'] = all_boxes[:, 3]\n",
        "    print('Run time: {:.2f}'.format(time.time() - start_time))\n",
        "    return res\n",
        "\n",
        "\n",
        "def ensemble(benchmark_csv, weights, params, get_score_init=True):\n",
        "    if get_score_init:\n",
        "        for bcsv in benchmark_csv:\n",
        "            print('Go for {}'.format(bcsv))\n",
        "            get_coco_score(bcsv)\n",
        "\n",
        "    ensemble_preds = ensemble_predictions(benchmark_csv, weights, params)\n",
        "    ensemble_preds.to_csv(\"ensemble.csv\", index=False)\n",
        "    get_coco_score(\"ensemble.csv\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if 0:\n",
        "        params = {\n",
        "            'run_type': 'nms',\n",
        "            'iou_thr': 0.5,\n",
        "            'verbose': True,\n",
        "        }\n",
        "    if 0:\n",
        "        params = {\n",
        "            'run_type': 'soft-nms',\n",
        "            'iou_thr': 0.5,\n",
        "            'thresh': 0.0001,\n",
        "            'sigma': 0.1,\n",
        "            'verbose': True,\n",
        "        }\n",
        "    if 0:\n",
        "        params = {\n",
        "            'run_type': 'nmw',\n",
        "            'skip_box_thr': 0.000000001,\n",
        "            'intersection_thr': 0.5,\n",
        "            'limit_boxes': 30000,\n",
        "            'verbose': True,\n",
        "        }\n",
        "\n",
        "    if 0:\n",
        "        params = {\n",
        "            'run_type': 'wbf',\n",
        "            'skip_box_thr': 0.001,\n",
        "            'intersection_thr': 0.7,\n",
        "            'conf_type': 'avg',\n",
        "            'limit_boxes': 30000,\n",
        "            'verbose': False,\n",
        "        }\n",
        "\n",
        "    if 1:\n",
        "        params = {\n",
        "            'run_type': 'wbf_exp',\n",
        "            'skip_box_thr': 0.001,\n",
        "            'intersection_thr': 0.7,\n",
        "            'conf_type': 'avg',\n",
        "            'limit_boxes': 30000,\n",
        "            'verbose': False,\n",
        "        }\n",
        "\n",
        "    in_dir = './benchmark/'\n",
        "    benchmark_csv = [\n",
        "        in_dir + 'EffNetB0-preds.csv',\n",
        "        in_dir + 'EffNetB0-mirror-preds.csv',\n",
        "        in_dir + 'EffNetB1-preds.csv',\n",
        "        in_dir + 'EffNetB1-mirror-preds.csv',\n",
        "        in_dir + 'EffNetB2-preds.csv',\n",
        "        in_dir + 'EffNetB2-mirror-preds.csv',\n",
        "        in_dir + 'EffNetB3-preds.csv',\n",
        "        in_dir + 'EffNetB3-mirror-preds.csv',\n",
        "        in_dir + 'EffNetB4-preds.csv',\n",
        "        in_dir + 'EffNetB4-mirror-preds.csv',\n",
        "        in_dir + 'EffNetB5-preds.csv',\n",
        "        in_dir + 'EffNetB5-mirror-preds.csv',\n",
        "        in_dir + 'EffNetB6-preds.csv',\n",
        "        in_dir + 'EffNetB6-mirror-preds.csv',\n",
        "        in_dir + 'EffNetB7-preds.csv',\n",
        "        in_dir + 'EffNetB7-mirror-preds.csv',\n",
        "        in_dir + 'DetRS-valid.csv',\n",
        "        in_dir + 'DetRS-mirror-valid.csv',\n",
        "        in_dir + 'DetRS_resnet50-valid.csv',\n",
        "        in_dir + 'DetRS_resnet50-mirror-valid.csv',\n",
        "        in_dir + 'yolov5x_tta.csv',\n",
        "    ]\n",
        "    weights = [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 5, 5, 7, 7, 9, 9, 8, 8, 5, 5, 10]\n",
        "    assert(len(benchmark_csv) == len(weights))\n",
        "    ensemble(\n",
        "        benchmark_csv,\n",
        "        weights,\n",
        "        params,\n",
        "        get_score_init=False\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    images = get_coco_annotations_data()\n",
        "\n",
        "    s = pd.read_csv('ensemble.csv', dtype={'img_id': np.str, 'label': np.str})\n",
        "    print(s)\n",
        "    out = np.zeros((len(s), 7), dtype=np.float64)\n",
        "    out[:, 0] = s['img_id']\n",
        "    ids = s['img_id'].astype(np.int32).values\n",
        "    x1 = s['x1'].values\n",
        "    x2 = s['x2'].values\n",
        "    y1 = s['y1'].values\n",
        "    y2 = s['y2'].values\n",
        "    print(x1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKfAz9RHjn5C",
        "outputId": "f069770e-6cb3-4d5d-a9b2-0a130187f4d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-e150208c1126>:3: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  s = pd.read_csv('ensemble.csv', dtype={'img_id': np.str, 'label': np.str})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        img_id label     score        x1        x2        y1        y2\n",
            "0         1000     1  0.877193  0.181975  0.308362  0.311871  0.796120\n",
            "1         1000     1  0.811741  0.789864  0.998597  0.398639  0.989925\n",
            "2         1000     1  0.788022  0.641403  0.819446  0.437056  0.992174\n",
            "3         1000     1  0.759509  0.413407  0.554443  0.202632  0.856473\n",
            "4         1000     1  0.753836  0.514914  0.650633  0.320370  0.978458\n",
            "...        ...   ...       ...       ...       ...       ...       ...\n",
            "2565828  99810    60  0.000064  0.724620  0.845660  0.804578  0.986928\n",
            "2565829  99810    62  0.000062  0.552200  0.651340  0.563102  0.835482\n",
            "2565830  99810    63  0.000062  0.642220  0.914480  0.776205  0.993253\n",
            "2565831  99810  53.0  0.000061  0.512520  0.970980  0.731265  0.991627\n",
            "2565832  99810    62  0.000061  0.315940  0.731460  0.395964  0.662380\n",
            "\n",
            "[2565833 rows x 7 columns]\n",
            "[0.18197502 0.78986394 0.64140266 ... 0.64222    0.5125201  0.31594   ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RSm2Wm7lYOjD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
